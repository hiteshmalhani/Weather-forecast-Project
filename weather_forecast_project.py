# -*- coding: utf-8 -*-
"""Weather forecast_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fa93MnyihUP6WDVwEi-mNE-Gmjf1jsni
"""

!pip install scikit-learn
!pip install nltk

import requests
import json
import pandas as pd
import numpy as np
import sqlite3
import statistics
import itertools
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from geopy.geocoders import Nominatim
import folium
import time
import pandas as pd
from flask import Flask, render_template

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv("/content/drive/MyDrive/Data set for project Weather forecast ")
data.head()

print(data.shape)

data['last_updated'] = data['last_updated'].astype(str)

data.head()

data=data.dropna()

data.tail()

data.dropna(thresh=10)

data_sample = data.sample(n=3500, random_state=42)
data_sample.shape

import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords
stop_words = stopwords.words('english')
data_sample['country'] = data_sample['country'].apply(lambda x: ''.join([word for word in x.split() if word not in (stop_words)]))

data_sample.head(15)

import re
pattern = r'[a-zA-z0-9!?:;"(,)]'
data_sample['sunset']=data_sample['sunset'].apply(lambda x: re.sub(pattern,'',x))

data_sample.head(30)

categories = data_sample['location_name'].unique()
for category in categories:
  print(category)

data_sample['location_name'] = data_sample['location_name'].str.replace('San Juan', '')



import pandas as pd
import matplotlib.pyplot as plt # Import matplotlib.pyplot

data = {'country': ['US', 'IN', 'UK', 'US', 'IN', 'US']}
data_sample = pd.DataFrame(data)

category_mapping = {
    'US': 'United States',
    'IN': 'India',
    'UK': 'United Kingdom',
}

category_counts = data_sample['country'].map(category_mapping).value_counts()

plt.figure(figsize=(10, 6)) # Now plt is defined and can be used
category_counts.plot(kind='bar', color='Pink')
plt.xlabel('Category')
plt.ylabel('Count')
plt.title('Count of Headings by Category')
plt.show()

data_sample.head()

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

import pandas as pd
import numpy as np
data = {'country': ['US', 'IN', 'UK', 'US', 'IN', 'US']}
data_sample = pd.DataFrame(data)
data_sample['temprature'] = np.random.randint(20, 35, size=len(data_sample))
Tfid_fVectorizer = TfidfVectorizer()
x_tfidf = Tfid_fVectorizer.fit_transform(data_sample['country'])
y = data_sample['temprature']

print(x_tfidf )

from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression # importing the LogisticRegression

data = {'country': ['US', 'IN', 'UK', 'US', 'IN', 'US']}
data_sample = pd.DataFrame(data)
data_sample['temprature'] = np.random.randint(20, 35, size=len(data_sample))

from sklearn.feature_extraction.text import TfidfVectorizer # Importing TfidfVectorizer
Tfid_fVectorizer = TfidfVectorizer()
x_tfidf = Tfid_fVectorizer.fit_transform(data_sample['country'])
y = data_sample['temprature']

x_train, x_test, y_train, y_test = train_test_split(x_tfidf, y, test_size=0.2, random_state=42)
classifier = LogisticRegression()
classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)
report = classification_report(y_test,y_pred)
print(report)